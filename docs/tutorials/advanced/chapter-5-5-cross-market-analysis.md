# Ch∆∞∆°ng 5.5: Ph√¢n T√≠ch ƒêa Th·ªã Tr∆∞·ªùng
## K·∫øt N·ªëi VPA Vi·ªát Nam V·ªõi Th·∫ø Gi·ªõi

### üéØ M·ª•c Ti√™u Ch∆∞∆°ng

Th·ªã tr∆∞·ªùng Vi·ªát Nam kh√¥ng t·ªìn t·∫°i ƒë·ªôc l·∫≠p. Ch∆∞∆°ng n√†y s·∫Ω d·∫°y b·∫°n c√°ch k·∫øt h·ª£p VPA v·ªõi ph√¢n t√≠ch th·ªã tr∆∞·ªùng to√†n c·∫ßu ƒë·ªÉ ƒë∆∞a ra quy·∫øt ƒë·ªãnh ch√≠nh x√°c h∆°n.

### üí° Nguy√™n L√Ω C·ªët L√µi

**"Hi·ªÉu d√≤ng ti·ªÅn to√†n c·∫ßu ƒë·ªÉ d·ª± ƒëo√°n VN th·ªã tr∆∞·ªùng"**

- üá∫üá∏ **S&P 500** ·∫£nh h∆∞·ªüng t√¢m l√Ω chung
- üá®üá≥ **Shanghai/Shenzhen** ·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp (xu·∫•t nh·∫≠p kh·∫©u)
- üíµ **USD/VND** ·∫£nh h∆∞·ªüng d√≤ng ti·ªÅn ngo·∫°i
- ‚ö° **Commodities** ·∫£nh h∆∞·ªüng HPG, PVS, VRE...

---

## üìö Ph·∫ßn 1: C∆° B·∫£n - Hi·ªÉu M·ªëi Li√™n H·ªá Th·ªã Tr∆∞·ªùng

### A. B·∫£n ƒê·ªì T√°c ƒê·ªông To√†n C·∫ßu

```python
def phan_tich_tac_dong_toan_cau(vn_stock_data, global_market_data):
    """
    Ph√¢n t√≠ch t√°c ƒë·ªông c·ªßa c√°c th·ªã tr∆∞·ªùng to√†n c·∫ßu l√™n c·ªï phi·∫øu VN
    
    Global factors:
    - US S&P 500 (t√¢m l√Ω risk-on/risk-off)
    - China CSI 300 (th∆∞∆°ng m·∫°i song ph∆∞∆°ng) 
    - USD/VND (d√≤ng ti·ªÅn ngo·∫°i)
    - DXY (USD Index) - s·ª©c m·∫°nh ƒë·ªìng USD
    - VIX (ch·ªâ s·ªë s·ª£ h√£i) - t√¢m l√Ω th·ªã tr∆∞·ªùng
    """
    
    correlations = {}
    impact_analysis = []
    
    # T√≠nh correlation v·ªõi c√°c ch·ªâ s·ªë to√†n c·∫ßu
    for global_index, global_data in global_market_data.items():
        
        # Align dates
        aligned_data = align_market_data(vn_stock_data, global_data)
        
        if len(aligned_data) > 20:  # ƒê·ªß d·ªØ li·ªáu ƒë·ªÉ t√≠nh
            correlation = calculate_rolling_correlation(
                aligned_data['vn_returns'], 
                aligned_data['global_returns'],
                window=20
            )
            
            correlations[global_index] = correlation
            
            # Ph√¢n t√≠ch impact timing
            impact_timing = analyze_impact_timing(
                aligned_data['vn_returns'],
                aligned_data['global_returns']
            )
            
            impact_analysis.append({
                'global_market': global_index,
                'avg_correlation': correlation.mean(),
                'correlation_trend': 'TƒÉng' if correlation.iloc[-10:].mean() > correlation.iloc[-30:-10].mean() else 'Gi·∫£m',
                'lead_lag': impact_timing['lead_lag_days'],  # +: VN theo sau, -: VN d·∫´n tr∆∞·ªõc
                'impact_strength': impact_timing['impact_strength'],
                'best_correlation_regime': impact_timing['best_regime']
            })
    
    return correlations, impact_analysis

def calculate_rolling_correlation(series1, series2, window=20):
    """T√≠nh correlation lƒÉn"""
    return series1.rolling(window).corr(series2)

def analyze_impact_timing(vn_returns, global_returns, max_lag=5):
    """Ph√¢n t√≠ch timing c·ªßa t√°c ƒë·ªông (ai ·∫£nh h∆∞·ªüng ai tr∆∞·ªõc)"""
    
    correlations_by_lag = {}
    
    for lag in range(-max_lag, max_lag + 1):
        if lag == 0:
            corr = np.corrcoef(vn_returns, global_returns)[0, 1]
        elif lag > 0:
            # Global market leads VN by 'lag' days
            corr = np.corrcoef(vn_returns[lag:], global_returns[:-lag])[0, 1]
        else:  # lag < 0
            # VN leads global by abs(lag) days
            corr = np.corrcoef(vn_returns[:lag], global_returns[-lag:])[0, 1]
        
        correlations_by_lag[lag] = abs(corr) if not np.isnan(corr) else 0
    
    # T√¨m lag c√≥ correlation cao nh·∫•t
    best_lag = max(correlations_by_lag.items(), key=lambda x: x[1])
    
    return {
        'lead_lag_days': best_lag[0],
        'impact_strength': best_lag[1],
        'best_regime': 'Global leads VN' if best_lag[0] > 0 else 'VN leads Global' if best_lag[0] < 0 else 'Simultaneous'
    }

# V√≠ d·ª• s·ª≠ d·ª•ng v·ªõi d·ªØ li·ªáu m√¥ ph·ªèng
def load_global_market_data():
    """Load d·ªØ li·ªáu th·ªã tr∆∞·ªùng to√†n c·∫ßu (m√¥ ph·ªèng)"""
    
    # Trong th·ª±c t·∫ø, d·ªØ li·ªáu n√†y ƒë∆∞·ª£c l·∫•y t·ª´ Yahoo Finance, Bloomberg, etc.
    return {
        'SP500': create_mock_global_data('S&P 500', 0.8),    # High correlation
        'CSI300': create_mock_global_data('China CSI300', 0.6),  # Medium correlation  
        'VIX': create_mock_global_data('VIX', -0.4),         # Negative correlation
        'DXY': create_mock_global_data('DXY', -0.3),         # Weak negative
        'USDVND': create_mock_global_data('USD/VND', -0.5)   # Medium negative
    }

def create_mock_global_data(name, base_correlation):
    """T·∫°o d·ªØ li·ªáu global m√¥ ph·ªèng"""
    np.random.seed(42)
    dates = pd.date_range('2024-01-01', periods=250, freq='D')
    
    # T·∫°o returns c√≥ correlation v·ªõi VN market
    vn_proxy_returns = np.random.normal(0.001, 0.02, 250)  # VN market proxy
    noise = np.random.normal(0, 0.015, 250)
    
    global_returns = base_correlation * vn_proxy_returns + np.sqrt(1 - base_correlation**2) * noise
    
    return pd.DataFrame({
        'date': dates,
        'returns': global_returns,
        'market': name
    })

# Ch·∫°y ph√¢n t√≠ch
vcb_data = pd.read_csv('market_data/VCB.csv')
global_data = load_global_market_data()

correlations, impacts = phan_tich_tac_dong_toan_cau(vcb_data, global_data)

print("=== PH√ÇN T√çCH T√ÅC ƒê·ªòNG TO√ÄN C·∫¶U ===")
for impact in impacts:
    print(f"\nüåç {impact['global_market']}:")
    print(f"   üìä Correlation TB: {impact['avg_correlation']:.3f}")
    print(f"   üìà Xu h∆∞·ªõng: {impact['correlation_trend']}")
    print(f"   ‚è±Ô∏è  Lead/Lag: {impact['lead_lag']} ng√†y ({impact['best_correlation_regime']})")
    print(f"   üí™ S·ª©c m·∫°nh t√°c ƒë·ªông: {impact['impact_strength']:.3f}")
```

### B. VPA Multi-Market Context

```python
def vpa_trong_boi_canh_toan_cau(vn_stock_data, global_sentiment):
    """
    ƒê√°nh gi√° t√≠n hi·ªáu VPA trong b·ªëi c·∫£nh th·ªã tr∆∞·ªùng to√†n c·∫ßu
    """
    
    vpa_signals = []
    
    for i in range(20, len(vn_stock_data)):
        current_day = vn_stock_data.iloc[i]
        historical_data = vn_stock_data.iloc[i-19:i+1]
        
        # T√≠n hi·ªáu VPA c∆° b·∫£n
        vpa_score = tinh_diem_tin_cay_stopping_volume(historical_data)
        
        # B·ªëi c·∫£nh to√†n c·∫ßu
        global_context = global_sentiment.get(current_day['date'], {})
        
        # ƒêi·ªÅu ch·ªânh VPA score theo global context
        adjusted_vpa_score = adjust_vpa_for_global_context(vpa_score, global_context)
        
        # Market regime (Risk-on vs Risk-off)
        market_regime = determine_market_regime(global_context)
        
        # Risk assessment
        risk_level = assess_global_risk(global_context, market_regime)
        
        vpa_signals.append({
            'date': current_day['date'],
            'price': current_day['close'],
            'base_vpa_score': vpa_score,
            'adjusted_vpa_score': adjusted_vpa_score,
            'market_regime': market_regime,
            'global_risk_level': risk_level,
            'recommendation': generate_global_aware_recommendation(
                adjusted_vpa_score, market_regime, risk_level
            ),
            'global_factors': global_context
        })
    
    return vpa_signals

def adjust_vpa_for_global_context(base_vpa_score, global_context):
    """
    ƒêi·ªÅu ch·ªânh ƒëi·ªÉm VPA d·ª±a tr√™n b·ªëi c·∫£nh to√†n c·∫ßu
    """
    adjusted_score = base_vpa_score
    
    # S&P 500 strong positive -> boost VPA signals
    if global_context.get('sp500_momentum', 0) > 0.02:  # S&P tƒÉng > 2%
        adjusted_score *= 1.2
    elif global_context.get('sp500_momentum', 0) < -0.02:  # S&P gi·∫£m > 2%
        adjusted_score *= 0.7
    
    # VIX (Fear index) high -> reduce confidence
    if global_context.get('vix_level', 20) > 30:  # VIX > 30 = high fear
        adjusted_score *= 0.6
    elif global_context.get('vix_level', 20) < 15:  # VIX < 15 = complacency
        adjusted_score *= 1.1
    
    # USD strength -> affects foreign flows
    if global_context.get('dxy_momentum', 0) > 0.01:  # USD m·∫°nh
        adjusted_score *= 0.8  # Harder for foreign money to flow in
    
    # China market (major trading partner)
    if global_context.get('china_momentum', 0) > 0.015:  # China strong
        adjusted_score *= 1.15
    elif global_context.get('china_momentum', 0) < -0.015:  # China weak
        adjusted_score *= 0.85
    
    return max(0, min(100, adjusted_score))

def determine_market_regime(global_context):
    """
    X√°c ƒë·ªãnh ch·∫ø ƒë·ªô th·ªã tr∆∞·ªùng hi·ªán t·∫°i
    """
    
    risk_on_signals = 0
    risk_off_signals = 0
    
    # S&P 500 momentum
    sp500_mom = global_context.get('sp500_momentum', 0)
    if sp500_mom > 0.01:
        risk_on_signals += 2
    elif sp500_mom < -0.01:
        risk_off_signals += 2
    
    # VIX level
    vix = global_context.get('vix_level', 20)
    if vix < 20:
        risk_on_signals += 1
    elif vix > 25:
        risk_off_signals += 1
    
    # USD/VND and foreign flows
    usdvnd_mom = global_context.get('usdvnd_momentum', 0)
    if usdvnd_mom < -0.005:  # VND strengthening
        risk_on_signals += 1
    elif usdvnd_mom > 0.005:  # VND weakening
        risk_off_signals += 1
    
    # China momentum
    china_mom = global_context.get('china_momentum', 0)
    if china_mom > 0.01:
        risk_on_signals += 1
    elif china_mom < -0.01:
        risk_off_signals += 1
    
    if risk_on_signals > risk_off_signals + 1:
        return "RISK-ON"
    elif risk_off_signals > risk_on_signals + 1:
        return "RISK-OFF"
    else:
        return "MIXED"

# Ch·∫°y ph√¢n t√≠ch VPA global-aware
global_sentiment_mock = create_mock_global_sentiment(vcb_data)
global_vpa_signals = vpa_trong_boi_canh_toan_cau(vcb_data, global_sentiment_mock)

print("\n=== VPA TRONG B·ªêI C·∫¢NH TO√ÄN C·∫¶U ===")
for signal in global_vpa_signals[-5:]:  # 5 t√≠n hi·ªáu g·∫ßn nh·∫•t
    print(f"\nüìÖ {signal['date']}:")
    print(f"   üí∞ VCB: {signal['price']:,}ƒë")
    print(f"   üìä VPA c∆° b·∫£n: {signal['base_vpa_score']:.0f}/100")
    print(f"   üåç VPA ƒëi·ªÅu ch·ªânh: {signal['adjusted_vpa_score']:.0f}/100")
    print(f"   üéØ Market regime: {signal['market_regime']}")
    print(f"   ‚ö†Ô∏è Risk level: {signal['global_risk_level']}")
    print(f"   üí° Recommendation: {signal['recommendation']}")
```

---

## üìà Ph·∫ßn 2: Th·ª±c H√†nh - Sector Rotation Global

### A. Theo D√µi V√≤ng Quay Ng√†nh To√†n C·∫ßu

```python
def phan_tich_sector_rotation_toan_cau(vn_sectors_data, global_sectors_data):
    """
    Ph√¢n t√≠ch v√≤ng quay ng√†nh to√†n c·∫ßu v√† ·∫£nh h∆∞·ªüng ƒë·∫øn VN
    
    VN Sectors: Banking, Real Estate, Steel, Consumer, Technology
    Global Sectors: Technology, Healthcare, Financials, Energy, Materials
    """
    
    sector_analysis = {}
    
    vn_sectors = {
        'Banking': ['VCB', 'TCB', 'BID', 'CTG', 'VPB'],
        'RealEstate': ['VIC', 'VHM', 'NVL', 'KDH', 'PDR'], 
        'Steel': ['HPG', 'HSG', 'NKG', 'TVN', 'TLH'],
        'Consumer': ['SAB', 'MSN', 'MCH', 'VNM', 'PNJ'],
        'Technology': ['CMG', 'ELC', 'ITD', 'CMT', 'ST8']
    }
    
    global_sectors = ['XLK', 'XLF', 'XLE', 'XLB', 'XLV']  # US Sector ETFs
    
    for vn_sector, vn_stocks in vn_sectors.items():
        
        # T√≠nh performance VN sector
        vn_sector_performance = calculate_sector_performance(vn_stocks, vn_sectors_data)
        
        # T√¨m global sector t∆∞∆°ng ·ª©ng
        corresponding_global = map_vn_to_global_sector(vn_sector)
        
        if corresponding_global in global_sectors_data:
            global_sector_performance = global_sectors_data[corresponding_global]
            
            # Ph√¢n t√≠ch correlation
            correlation = analyze_sector_correlation(
                vn_sector_performance, 
                global_sector_performance
            )
            
            # Lead/lag analysis
            lead_lag = analyze_sector_lead_lag(
                vn_sector_performance,
                global_sector_performance
            )
            
            # Rotation prediction
            rotation_signal = predict_sector_rotation(
                vn_sector_performance,
                global_sector_performance,
                correlation,
                lead_lag
            )
            
            sector_analysis[vn_sector] = {
                'correlation_with_global': correlation,
                'lead_lag_days': lead_lag,
                'current_relative_strength': calculate_relative_strength(vn_sector_performance),
                'rotation_signal': rotation_signal,
                'recommended_action': generate_sector_recommendation(rotation_signal),
                'top_stocks_in_sector': rank_stocks_in_sector(vn_stocks, vn_sectors_data),
                'global_sector_trend': analyze_global_sector_trend(global_sector_performance)
            }
    
    return sector_analysis

def predict_sector_rotation(vn_performance, global_performance, correlation, lead_lag):
    """
    D·ª± ƒëo√°n v√≤ng quay ng√†nh d·ª±a tr√™n:
    1. Global sector momentum
    2. VN sector relative performance  
    3. Historical correlation patterns
    """
    
    # Global sector momentum (10 ng√†y g·∫ßn nh·∫•t)
    global_momentum = global_performance['returns'][-10:].mean()
    
    # VN sector momentum
    vn_momentum = vn_performance['returns'][-10:].mean()
    
    # Relative performance vs benchmark
    vn_vs_market = vn_momentum - 0.001  # Assume market return = 0.1%/day
    
    signals = []
    
    # Signal 1: Global sector rotating in
    if global_momentum > 0.005 and correlation > 0.4:  # Strong global momentum + correlation
        if lead_lag > 0:  # Global leads VN
            signals.append(('ROTATION_IN_COMING', 0.7))
        else:
            signals.append(('ROTATION_IN_NOW', 0.8))
    
    # Signal 2: VN sector outperforming global
    if vn_vs_market > 0.002 and global_momentum < 0:
        signals.append(('VN_SECTOR_STRONG', 0.6))
    
    # Signal 3: Sector rotation out
    if global_momentum < -0.005 and correlation > 0.3:
        signals.append(('ROTATION_OUT_WARNING', 0.6))
    
    # Combine signals
    if not signals:
        return {'signal': 'NEUTRAL', 'strength': 0.5, 'reasoning': 'No clear rotation signal'}
    
    # Take strongest signal
    strongest_signal = max(signals, key=lambda x: x[1])
    
    return {
        'signal': strongest_signal[0],
        'strength': strongest_signal[1],
        'reasoning': generate_rotation_reasoning(strongest_signal, global_momentum, vn_momentum)
    }

# Ch·∫°y ph√¢n t√≠ch sector rotation
print("=== PH√ÇN T√çCH SECTOR ROTATION TO√ÄN C·∫¶U ===")
print("üîÑ Tracking global sector rotation impact on Vietnam sectors...")

# Mock data for demonstration
vn_sectors_mock = create_mock_vn_sectors_data()
global_sectors_mock = create_mock_global_sectors_data()

sector_rotation_analysis = phan_tich_sector_rotation_toan_cau(vn_sectors_mock, global_sectors_mock)

for sector, analysis in sector_rotation_analysis.items():
    print(f"\nüè≠ {sector}:")
    print(f"   üåç Correlation v·ªõi Global: {analysis['correlation_with_global']:.3f}")
    print(f"   ‚è±Ô∏è Lead/Lag: {analysis['lead_lag_days']} ng√†y")
    print(f"   üìà Relative Strength: {analysis['current_relative_strength']:.2f}")
    print(f"   üîÑ Rotation Signal: {analysis['rotation_signal']['signal']}")
    print(f"   üí™ Signal Strength: {analysis['rotation_signal']['strength']:.1%}")
    print(f"   üí° Recommended Action: {analysis['recommended_action']}")
```

---

## üîç Ph·∫ßn 3: N√¢ng Cao - Event-Driven Analysis

> üí° **L∆∞u √Ω**: Ph·∫ßn n√†y d√†nh cho ng∆∞·ªùi mu·ªën hi·ªÉu v·ªÅ event-driven trading. 
> N·∫øu b·∫°n m·ªõi b·∫Øt ƒë·∫ßu, c√≥ th·ªÉ **b·ªè qua** v√† quay l·∫°i sau.

### A. Theo D√µi S·ª± Ki·ªán To√†n C·∫ßu

```python
class GlobalEventTracker:
    def __init__(self):
        self.event_impact_history = {}
        self.event_types = {
            'fed_meeting': {'impact_duration': 3, 'volatility_multiplier': 1.5},
            'china_data': {'impact_duration': 2, 'volatility_multiplier': 1.2},
            'geopolitical': {'impact_duration': 7, 'volatility_multiplier': 2.0},
            'commodity_shock': {'impact_duration': 5, 'volatility_multiplier': 1.8},
            'currency_intervention': {'impact_duration': 2, 'volatility_multiplier': 1.3}
        }
    
    def track_upcoming_events(self):
        """
        Theo d√µi c√°c s·ª± ki·ªán quan tr·ªçng s·∫Øp t·ªõi
        """
        
        # Economic calendar (normally from API)
        upcoming_events = [
            {
                'date': '2025-07-30',
                'event': 'Fed Interest Rate Decision',
                'type': 'fed_meeting',
                'importance': 'HIGH',
                'expected_impact': {
                    'VN_stocks': 'HIGH',
                    'VND': 'MEDIUM', 
                    'foreign_flows': 'HIGH'
                }
            },
            {
                'date': '2025-07-25',
                'event': 'China Manufacturing PMI',
                'type': 'china_data',
                'importance': 'MEDIUM',
                'expected_impact': {
                    'VN_export_stocks': 'MEDIUM',
                    'commodities': 'MEDIUM'
                }
            }
        ]
        
        return upcoming_events
    
    def analyze_pre_event_positioning(self, vn_stock_data, event_date, event_type):
        """
        Ph√¢n t√≠ch positioning tr∆∞·ªõc s·ª± ki·ªán
        """
        
        # T√¨m d·ªØ li·ªáu 10 ng√†y tr∆∞·ªõc event
        event_date_obj = pd.to_datetime(event_date)
        pre_event_data = vn_stock_data[
            (pd.to_datetime(vn_stock_data['date']) >= event_date_obj - pd.Timedelta(days=10)) &
            (pd.to_datetime(vn_stock_data['date']) < event_date_obj)
        ]
        
        if len(pre_event_data) < 5:
            return None
        
        # Ph√¢n t√≠ch volume patterns
        volume_trend = analyze_volume_trend_pre_event(pre_event_data)
        
        # Ph√¢n t√≠ch price positioning
        price_positioning = analyze_price_positioning_pre_event(pre_event_data)
        
        # VPA signals tr∆∞·ªõc event
        vpa_signals_pre_event = []
        for i in range(5, len(pre_event_data)):
            window_data = pre_event_data.iloc[i-4:i+1]
            vpa_score = tinh_diem_tin_cay_stopping_volume_simple(window_data, pre_event_data.iloc[i])
            if vpa_score > 60:
                vpa_signals_pre_event.append(vpa_score)
        
        return {
            'volume_trend': volume_trend,
            'price_positioning': price_positioning,
            'vpa_signals_count': len(vpa_signals_pre_event),
            'avg_vpa_strength': np.mean(vpa_signals_pre_event) if vpa_signals_pre_event else 0,
            'positioning_risk': assess_pre_event_risk(volume_trend, price_positioning),
            'recommended_strategy': recommend_pre_event_strategy(
                volume_trend, price_positioning, event_type
            )
        }
    
    def backtest_event_impact(self, historical_events, stock_data):
        """
        Backtest impact c·ªßa c√°c events l·ªãch s·ª≠
        """
        
        event_performance = []
        
        for event in historical_events:
            event_date = pd.to_datetime(event['date'])
            event_type = event['type']
            
            # T√¨m d·ªØ li·ªáu around event date
            event_data = stock_data[
                (pd.to_datetime(stock_data['date']) >= event_date - pd.Timedelta(days=5)) &
                (pd.to_datetime(stock_data['date']) <= event_date + pd.Timedelta(days=10))
            ]
            
            if len(event_data) < 10:
                continue
            
            # T√≠nh performance pre vs post event
            pre_event_price = event_data[event_data['date'] <= event['date']]['close'].iloc[-1]
            
            impact_duration = self.event_types[event_type]['impact_duration']
            post_event_data = event_data[event_data['date'] > event['date']]
            
            if len(post_event_data) >= impact_duration:
                post_event_price = post_event_data['close'].iloc[impact_duration-1]
                event_return = (post_event_price - pre_event_price) / pre_event_price
                
                event_performance.append({
                    'event_type': event_type,
                    'event_return': event_return,
                    'volatility_increase': calculate_volatility_increase(event_data, event_date),
                    'volume_spike': calculate_volume_spike(event_data, event_date)
                })
        
        # Ph√¢n t√≠ch th·ªëng k√™
        performance_stats = {}
        for event_type in self.event_types.keys():
            type_events = [e for e in event_performance if e['event_type'] == event_type]
            
            if type_events:
                returns = [e['event_return'] for e in type_events]
                performance_stats[event_type] = {
                    'avg_return': np.mean(returns),
                    'volatility': np.std(returns),
                    'win_rate': sum(1 for r in returns if r > 0) / len(returns),
                    'max_return': max(returns),
                    'min_return': min(returns)
                }
        
        return performance_stats

# S·ª≠ d·ª•ng Event Tracker
event_tracker = GlobalEventTracker()
upcoming_events = event_tracker.track_upcoming_events()

print("\n=== GLOBAL EVENT ANALYSIS ===")
print("üìÖ Upcoming High-Impact Events:")

for event in upcoming_events:
    print(f"\nüóìÔ∏è {event['date']}: {event['event']}")
    print(f"   ‚ö†Ô∏è Importance: {event['importance']}")
    print(f"   üìä Expected Impact:")
    for asset, impact in event['expected_impact'].items():
        print(f"      ‚Ä¢ {asset}: {impact}")
    
    # Pre-event positioning analysis
    pre_analysis = event_tracker.analyze_pre_event_positioning(
        vcb_data, event['date'], event['type']
    )
    
    if pre_analysis:
        print(f"   üí° Pre-Event Strategy: {pre_analysis['recommended_strategy']}")
        print(f"   ‚ö†Ô∏è Positioning Risk: {pre_analysis['positioning_risk']}")
```

---

## üìã T√≥m T·∫Øt Ch∆∞∆°ng

### Nh·ªØng G√¨ ƒê√£ H·ªçc:
1. **Cross-market correlation** - Hi·ªÉu m·ªëi li√™n h·ªá VN v·ªõi th·∫ø gi·ªõi
2. **Global-aware VPA** - ƒêi·ªÅu ch·ªânh t√≠n hi·ªáu VPA theo b·ªëi c·∫£nh to√†n c·∫ßu
3. **Sector rotation tracking** - Theo d√µi v√≤ng quay ng√†nh to√†n c·∫ßu
4. **Event-driven analysis** - Ph√¢n t√≠ch t√°c ƒë·ªông s·ª± ki·ªán kinh t·∫ø (n√¢ng cao)

### L·ª£i √çch Thi·∫øt Th·ª±c:
- ‚úÖ **Tr√°nh ƒë∆∞·ª£c b·∫´y** - Kh√¥ng mua khi global sentiment x·∫•u
- ‚úÖ **Timing t·ªët h∆°n** - Bi·∫øt khi n√†o n√™n aggressive, khi n√†o defensive
- ‚úÖ **Sector selection** - Ch·ªçn ng√†nh ƒëang ƒë∆∞·ª£c favor globally
- ‚úÖ **Risk management** - Gi·∫£m position tr∆∞·ªõc events l·ªõn

### Ma Tr·∫≠n Quy·∫øt ƒê·ªãnh:
| Global Context | VPA Signal Strong | VPA Signal Weak |
|----------------|-------------------|-----------------|
| Risk-On + China Strong | üü¢ STRONG BUY | üîµ HOLD/WATCH |
| Risk-Off + High VIX | üü° WAIT | üî¥ AVOID |
| Mixed + USD Weak | üîµ CAUTIOUS BUY | üü° NEUTRAL |

### Ch∆∞∆°ng Ti·∫øp Theo:
**Ch∆∞∆°ng 5.6: H·ªá Th·ªëng C·∫£nh B√°o Th√¥ng Minh** - X√¢y d·ª±ng system theo d√µi 24/7 v√† c·∫£nh b√°o realtime khi c√≥ c∆° h·ªôi.